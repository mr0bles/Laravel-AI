### Variables
@defaultModel = deepseek-coder-v2:lite
@temperature = 0.7
@top_p = 0.9

### LLM Endpoints

### Generar respuesta con LLM
POST {{baseUrl}}/llm/generate
Content-Type: application/json

{
    "prompt": "¿Cuál es el mejor equipo de futbol de españa?",
    "model": "{{defaultModel}}",
    "options": {
        "temperature": {{temperature}},
        "top_p": {{top_p}}
    }
}

### Obtener lista de modelos disponibles
GET {{baseUrl}}/llm/models

### Obtener información de un modelo específico
GET {{baseUrl}}/llm/models/{{defaultModel}}
