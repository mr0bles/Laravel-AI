### Variables
@customModel = deepseek-coder
@temperature = 0.7
@top_p = 0.9

### LLM Endpoints

### Generar respuesta con LLM
POST {{baseUrl}}/llm/generate
Content-Type: application/json

{
    "prompt": "¿Cuál es el mejor equipo de futbol de españa?"
}

### Generar respuesta con LLM con parametros
POST {{baseUrl}}/llm/generate
Content-Type: application/json

{
    "prompt": "¿Cual es la mejor manera de eliminar un valor por valor en un array en PHP 8.4?",
    "model": "{{customModel}}",
    "options": {
        "temperature": {{temperature}},
        "top_p": {{top_p}}
    }
}

### Obtener embedding
POST {{baseUrl}}/llm/embedding
Content-Type: application/json
Accept: application/json

{
    "prompt": "Este es un texto de ejemplo para obtener su embedding"
}

### Chat
POST {{baseUrl}}/llm/chat
Content-Type: application/json
Accept: application/json

{
    "messages": [
        {
            "role": "system",
            "content": "Eres un asistente útil y amigable."
        },
        {
            "role": "user",
            "content": "Soy Robles de Badajoz?"
        },
        {
            "role": "assistant",
            "content": "encantado, ¿cómo estás?"
        },
        {
            "role": "user",
            "content": "Bien, ¿sabes de donde soy?"
        }
    ]
}

### Chat con parametros
POST {{baseUrl}}/llm/chat
Content-Type: application/json
Accept: application/json

{
    "messages": [
        {
            "role": "system",
            "content": "Eres programador experto Laravel."
        },
        {
            "role": "user",
            "content": "Cree el modelo Person"
        },
        {
            "role": "assistant",
            "content": "¿Fue bien?"
        },
        {
            "role": "user",
            "content": "Me dio error, ¿que puedo mirar?"
        }
    ],
    "options": {
        "model": "{{customModel}}",
        "temperature": {{temperature}},
        "top_p": {{top_p}}
    }
}

### Obtener lista de modelos disponibles
GET {{baseUrl}}/llm/models

### Obtener información de un modelo específico
GET {{baseUrl}}/llm/models/{{customModel}}
